# Production Docker Compose for AI School Platform
# Deploy on thestai.com with Caddy, PostgreSQL, and Ollama

version: '3.8'

services:
  # Reverse Proxy with automatic SSL
  caddy:
    image: caddy:2-alpine
    container_name: caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      nextjs:
        condition: service_healthy
    networks:
      - frontend

  # Next.js Application
  nextjs:
    image: ghcr.io/${GITHUB_REPOSITORY:-ai-school}/ai-school-platform:${IMAGE_TAG:-latest}
    container_name: nextjs
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${DB_USER:-ai_school}:${DB_PASSWORD}@postgres:5432/${DB_NAME:-ai_school}
      - DIRECT_URL=postgresql://${DB_USER:-ai_school}:${DB_PASSWORD}@postgres:5432/${DB_NAME:-ai_school}
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET}
      - NEXTAUTH_URL=https://${DOMAIN:-thestai.com}
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen3:8b}
      # Optional: Claude API fallback
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - AI_MODEL=${AI_MODEL:-}
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    networks:
      - frontend
      - backend
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${DB_USER:-ai_school}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME:-ai_school}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-ai_school} -d ${DB_NAME:-ai_school}"]
      interval: 10s
      timeout: 5s
      retries: 5
    # Performance tuning for 8GB RAM VPS
    command:
      - "postgres"
      - "-c"
      - "max_connections=100"
      - "-c"
      - "shared_buffers=256MB"
      - "-c"
      - "effective_cache_size=768MB"
      - "-c"
      - "maintenance_work_mem=64MB"
      - "-c"
      - "checkpoint_completion_target=0.9"
      - "-c"
      - "wal_buffers=16MB"
      - "-c"
      - "random_page_cost=1.1"

  # Local AI with Ollama
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - backend
    # Resource limits for shared VPS
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          memory: 4G

  # Automated PostgreSQL Backups
  backup:
    image: prodrigestivill/postgres-backup-local:16-alpine
    container_name: backup
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_DB=${DB_NAME:-ai_school}
      - POSTGRES_USER=${DB_USER:-ai_school}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - SCHEDULE=@daily
      - BACKUP_KEEP_DAYS=7
      - BACKUP_KEEP_WEEKS=4
      - BACKUP_KEEP_MONTHS=3
      - HEALTHCHECK_PORT=8080
    volumes:
      - backup_data:/backups
    networks:
      - backend

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
    internal: true  # No direct internet access for backend services

volumes:
  caddy_data:
  caddy_config:
  postgres_data:
  ollama_data:
  backup_data:
